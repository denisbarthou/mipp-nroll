%===========================================================
%                              Choix de thÃ©matique
%===========================================================
% Une des quatre options 'parallelisme', 'architecture', 'systeme' 
% 'tempsreel' doit Ãªtre utilisÃ©e avec le style compas2021
\documentclass[sigconf,review]{acmart}

\usepackage{listings}
\usepackage{algorithmicx}
\usepackage[noend]{algpseudocode}
\usepackage{algorithm,hhline}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{subcaption}
\usepackage{color}

\definecolor{light-gray}{gray}{0.80}
%===========================================================
%                               Title
%===========================================================
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=C,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}
\lstset{emph={%  
    in%
    },emphstyle={\color{red}\bfseries}%
}%
\begin{document}
\bibliographystyle{plain}

\lstset{
  language=C,
  basicstyle=\tiny\ttfamily,
%  numbers=left,
%  xleftmargin=2em,
  frame=single,
%  framexleftmargin=2em,
  escapeinside={(*}{*)}
}

\title{Exploring Vectorization and unrolling with SMT}

\author{Denis Barthou}
\affiliation{\institution{Bordeaux Institute of Technology} \city{Bordeaux} \country{France}}
\author{Edgar Baucher}
\affiliation{\institution{Bordeaux Institute of Technology} \city{Bordeaux} \country{France}}
\author{Ahmed-Manaf Dhamani}
\affiliation{\institution{Bordeaux Institute of Technology} \city{Bordeaux} \country{France}}
\author{William Jalby}
\affiliation{\institution{University of Versailles Saint Quentin} \city{Versailles} \country{France}}


%\date{\today}

%===========================================================         %
%Abstract
%===========================================================  
\begin{abstract}
  
\end{abstract}
\keywords{}

\maketitle



\section{Introduction}
The high performance kernels require multiple optimizations. We do not
focus particularly on codes from libraries, but rather on kernels from
applications. One of the objectives is to study how to generate
efficient source code, while still keeping the code portable,
understandable by users and allowing composition. As a counterpart, we
may not wish to reach top performance but this would be suficient to
stay close to it (let us say 80\% of the top performance) if this
allows portability, maintenance and composability.

Many optimizations at the loop level and targeting cache/memory
hierarchy are well known and can be handled by dedicated compiler
optimizations. We will focus here on code optimizations for codes that
run in a tile of data fitting in cache (or that does not have
reuse). Essentially, the optimizations concerned are instruction
scheduling (notably through loop transformations), SIMDization,
register allocation. Besides, we assume the user selects SIMD
instructions, using for instance a library such as the C++ MIPP
wrapper \cite{mipp}. We therefore focus on a very narrow optimization
space, playing only with loop unrolling and letting to the compiler
deal with instruction scheduling and register allocation.  The
advantage of this approach is that this is only source code and
compiler variations, hence allows composition of codes.  The
particularities of the kernels and vectorization with MIPP are
recalled here:
\begin{itemize}
  \item Vector instructions will be parametrized by their length VL (expressed in elements) so the code should be generic and cover all possible Vector Lengths
\item All instructions will be not differentiated with respect to DP versus SP. It will be the optimizer which will take care of that specialization.
\item All arithmetic instructions will operate between registers (à la ARM): no operand coming from memory can be used in an arithmetic instruction. Potentially, this characteristic increases register pressure where a combined load/arithmetic operation could avoid unnecessary use of registers. This characteristic is compatible though with C++ library such as MIPP. 
\item All arithmetic instructions will use only Vector Registers as main operands no scalar registers can be used. This will require the use of Broadcast instructions to promote a scalar to vector.
\item We will use a Vector Reduction (denoted VRED) instruction capable of summing all of the components of a vector register. Such an instruction is available in ARM ISA but currently it requires a chain of between 4 and 6 instructions on X86
\item The code to by duplicated (through unrolling) will be enclosed between curly brackets. 
\item The instruction selection for vectorized code is assumed to be done by the user through MIPP. Indeed, while efficient instruction selection methods exist in current compilers, this is still limited to linear algebra codes. MIPP (or existing alternatives) removes this issue by proposing a wider access to intrinsics SIMD instructions.
\end{itemize}
Instruction scheduling and register allocation are two key optimizations that must be performed in order to reach high level performance code. Two possibilities: either the user specifies in high level ASM both of them, or the compiler is in charge. 

\section{Matrix product, stored row-wise}
The matrx code is a kernel for libraries, but still there may be occurences of special matrix sizes that are not perfectly addressed by libraries. We will start with small rectangular bloc sizes first. In the code presented in Fig.\ref{fig:gemm}, all loops are potentially unrolled. Variables \texttt{ui}, \texttt{uj}, \texttt{uk}
are indices corresponding to the unrolling factors. The unrolling on k
produces a sequence of FMAs. This does not improve ILP for FMA but
this enhances register reuse and can help to hide other instruction
latencies (loads).  There is no tail code on purpose, the sizes BI,
BJ, BK are adjusted to the unrolling factors, while still keeping the
global size of matrices A,B and C within 5\% of the chosen global
size, for all unrolling factors.  The unrolling factors from 1 to 15
have been explored to evaluate the capacity of the compilers to
allocate registers and reschedule. We have limited the exploration of
the register block size $UI*UJ+UI*UK+UJ*UK$ so that it does not exceed
twice the amount of SIMD registers (so 64 for AVX512, 32 for AVX), and
$UJ*VL$ should not exceed the size of the dimension BJ.  The type of the elements are defined by \texttt{TYPE} . The above code
is written using a template mechanism that is instantiated
into C++ code for all unrolling factors.  The first machine of the
evaluation is an Intel Cascade Lake 6230R with AVX-512. The compilers
evaluated are, with flag -O3: icc version 19.1.3.304, icc version 2021
(dpc++ OneAPI), Clang 15 with 3 register allocation methods, greedy
(base), basic and PBQP, and GCC version 11.9.


\begin{figure}
  \begin{lstlisting}
for (int i=0;i<BLOCKI;i+=ui) {                
  for (int j=0;j<BLOCKJ;j+= uj*nv) {           
    { ii in [0,ui],jj in [0,uj]:
        mipp::Reg<TYPE> c_ii,jj;
        c_{ii,jj}.load(&C[(i + ii )*BLOCKJ + j + jj *nv]);
    }                
    for (int k=0;k<BLOCKK;k+= uk ) {            
      { ii in [0,ui],kk in [0,uk]:
          mipp::Reg<TYPE> a{{ ii }}{{ kk }};
          a_{ii,kk} = mipp::set1<TYPE>(A[(i + ii )*BLOCKK+k+ kk ]);
      }
      { jj in [0,uj],kk in [0,uk]:
          mipp::Reg<TYPE> b{{ kk }}{{ jj }};
          b_{kk,jj}.load(&B[(k+ kk )*BLOCKJ + j + jj*nv]);
      }    
      { ii in [0,ui], jj in [0,uj] :
          c_{ii,jj} = { k in [0,uk]: mipp::fmadd(a_ii,kk, b_kk,jj, } , c_ii,jj  { k in [0,uk]: ) };
      }
    }
    { ii in [0,ui],jj in [0,uj]:
        c_ii,jj.store(&C[(i+ ii )*BLOCKJ + j + ( jj )*nv]);      
    }
  }
}
  \end{lstlisting}
  \caption{Matrix product vectorized and unrolled\label{fig:gemm}. \texttt{in} constructs correspond to unrolled statements/expressions. }
\end{figure}


\subsection{Performance evaluation with double on Intel CascadeLake}
\begin{figure*}[ht]
  \begin{subfigure}[h]{0.45\textwidth}
  \includegraphics[width=\textwidth]{../benches/gemm/cascadelake-64x256x64/icc-2021.2.0.pdf}
  \caption{icc 2021.2.0}
  \end{subfigure}
  \begin{subfigure}[h]{0.45\textwidth}  
\includegraphics[width=\textwidth]{../benches/gemm/cascadelake-64x256x64/icc-19.1.3.pdf}
  \caption{icc 19.1.3}
  \end{subfigure}
  \begin{subfigure}[h]{0.45\textwidth}  
\includegraphics[width=\textwidth]{../benches/gemm/cascadelake-64x256x64/pbqp.pdf}
  \caption{Clang 15 with PBQP register allocation}
  \end{subfigure}
  \begin{subfigure}[h]{0.45\textwidth}  
\includegraphics[width=\textwidth]{../benches/gemm/cascadelake-64x256x64/greedy.pdf}
  \caption{Clang 15 with greedy register allocation}
  \end{subfigure}
  \begin{subfigure}[h]{0.45\textwidth}  
\includegraphics[width=\textwidth]{../benches/gemm/cascadelake-64x256x64/basic.pdf}
  \caption{Clang 15 with basic register allocation}
  \end{subfigure}
  \begin{subfigure}[h]{0.45\textwidth}  
\includegraphics[width=\textwidth]{../benches/gemm/cascadelake-64x256x64/gcc-11.9.pdf}
  \caption{GCC 11.9}
  \end{subfigure}\hfill ~
  \caption{Block DGEMM Performance used on Intel CascadeLake with different compilers. The block (BI,BK,BJ) is 64x256x64. Each code represent a different register block size, obtained through the three unrolling factors. Codes with register block size $\leq 32$ are in blue (fit in register whatever the schedule), others in red.  \label{fig:cascadelake}}
\end{figure*}
 For all plots in Fig.\ref{fig:cascadelake}, the same codes with the same vectorization expressed with MIPP are
compiled. Points shown in blue correspond to codes that should not require
more SIMD registers than the physical registers (32 here, shown by the vertical red line), whatever
the scheduling chosen by the compiler. This is not the case for codes
shown in red, some schedules may manage to use only registers while
others will require spill code. The graphs show performance and the
cumulated register count required by the code, included the space on
the stack used by the spill. For instance, a value of 40 registers and
spill used indicates that the compiler was able to use all 32
registers and 8 additional spaces on the stack. With the exception of
GCC, other compilers manage to allocate less than 32 registers for all
blue codes. The max performance on this machine is normally 32 flops/cycles (with 2 FMAs operating on AVX512 vectors).  

There is no significant difference between icc version 2021 and Clang 15, either greedy or PBQP register allocations. This is expected since icc now is based on LLVM. GCC however fails significanlty, reaching  only 24 flop/cycle while other compilers reach 30-31 flop/cycle. 
\begin{figure*}[ht]
  \begin{subfigure}[h]{0.45\textwidth}
  \includegraphics[width=\textwidth]{../benches/gemm/cascadelake-64x256x64/icc21xicc19.pdf}
  \caption{icc 2021.2.0 compared with icc 19.1.3}
  \end{subfigure}
  \begin{subfigure}[h]{0.45\textwidth}  
\includegraphics[width=\textwidth]{../benches/gemm/cascadelake-64x256x64/gccxgreedy.pdf}
  \caption{gcc 11.9 compared with clang 15}
  \end{subfigure}
  \caption{Correlation of code performance on CascadeLake between different compilers.\label{fig:cascadelakecorrelation}}
\end{figure*}


\begin{figure*}[ht]
  \includegraphics[width=0.45\textwidth]{../benches/gemm/cascadelake-64x256x64/icc21loc.pdf}
  \caption{Performance wrt lines of source code}
\end{figure*}
The best codes for icc 2021 are: 8x2x3 (32/46), 8x1x3 (30/35), 7x3x3 (32/51), 7x2x3 (28/41), 6x4x3 (32/54), 6x3x4 (29/54), 6x3x3


\subsection{Performance evaluation with double on ArmThunderX2}
The codes considered are exactly the same as before (portability).  Due to the architecture of the processor, supporting a SMT of 4, we compared performance for a single thread and performance with 4 threads, both on a single core. 

\begin{figure*}[ht]
  \begin{subfigure}[h]{0.45\textwidth}
  \includegraphics[width=\textwidth]{../benches/gemm/arm-64x256x64/greedy.pdf}
  \caption{clang 15}
  \end{subfigure}
  \begin{subfigure}[h]{0.45\textwidth}  
\includegraphics[width=\textwidth]{../benches/gemm/arm-64x256x64/openmp.pdf}
  \caption{clang 15 with OpenMP, SMT of 4}
  \end{subfigure}
  \begin{subfigure}[h]{0.45\textwidth}  
\includegraphics[width=\textwidth]{../benches/gemm/arm-64x256x64/clangxsmt.pdf}
  \caption{Correlation between Clang 15 without and with SMT4}
  \end{subfigure}
  \caption{Block DGEMM Performance used on Arm ThunderX2 with different compilers. The block (BI,BK,BJ) is 64x256x64. Each code represent a different register block size, obtained through the three unrolling factors. Codes with register block size $\leq 32$ are in blue (fit in register whatever the schedule), others in red. (c) show correlation between the two plots. \label{fig:cascadelake}}
\end{figure*}

\section{Related Works}
\section{Conclusion}
\label{sec:conclusion}

\bibliography{biblio}

\end{document}
